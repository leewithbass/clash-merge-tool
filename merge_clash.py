import requests
import base64
import yaml
from urllib.parse import urlparse, unquote
import re
from rich.console import Console
from rich.prompt import Prompt
from rich.progress import Progress, SpinnerColumn, TextColumn
from rich.table import Table

# åˆå§‹åŒ– rich æ§åˆ¶å°
console = Console()

def get_subscription_urls():
    """è·å–ç”¨æˆ·è¾“å…¥çš„è®¢é˜…é“¾æ¥"""
    urls = []
    console.print("[bold cyan]è¯·è¾“å…¥è®¢é˜…é“¾æ¥ï¼Œæ¯è¡Œä¸€ä¸ªã€‚è¾“å…¥ç©ºè¡Œæˆ– 'done' ç»“æŸ:[/bold cyan]")
    while True:
        try:
            url = input().strip()
            if not url or url.lower() == 'done':
                break
            if url.startswith("http"):
                urls.append(url)
            else:
                console.print("[bold red]æ— æ•ˆçš„é“¾æ¥ï¼Œè¯·ç¡®ä¿ä»¥ http æˆ– https å¼€å¤´ã€‚[/bold red]")
        except (EOFError, KeyboardInterrupt):
            # å¦‚æœé‡åˆ°EOFæˆ–ä¸­æ–­ä¿¡å·ï¼Œè·³å‡ºå¾ªç¯
            break
    return urls

def decode_subscription_content(content):
    """è§£ç  Base64 ç¼–ç çš„è®¢é˜…å†…å®¹"""
    # é¦–å…ˆæ£€æŸ¥å†…å®¹æ˜¯å¦å·²ç»æ˜¯æ˜æ–‡ï¼ˆä¸æ˜¯Base64ç¼–ç ï¼‰
    try:
        # å¦‚æœå†…å®¹å¯ä»¥è¢«è§£æä¸ºURLæˆ–åŒ…å«æ˜æ˜¾çš„æ˜æ–‡ç‰¹å¾ï¼Œåˆ™è®¤ä¸ºå®ƒå·²ç»æ˜¯æ˜æ–‡
        if content.startswith("ss://") or "://" in content:
            return content
    except:
        pass
    
    # ç¡®ä¿å†…å®¹æ˜¯å­—èŠ‚ç±»å‹
    if isinstance(content, str):
        # å…ˆå°è¯•ç›´æ¥ç¼–ç ä¸ºASCII
        try:
            content = content.encode('ascii')
        except UnicodeEncodeError:
            # å¦‚æœåŒ…å«éASCIIå­—ç¬¦ï¼Œå¯èƒ½å·²ç»è§£ç è¿‡äº†
            return content
    
    # å°è¯•ç›´æ¥è§£ç 
    try:
        # ä¿®å¤Base64å¡«å……
        missing_padding = len(content) % 4
        if missing_padding:
            content += b'=' * (4 - missing_padding)
        decoded_bytes = base64.b64decode(content)
        return decoded_bytes.decode('utf-8')
    except Exception as e1:
        try:
            # å¦‚æœç›´æ¥è§£ç å¤±è´¥ï¼Œå°è¯• URL å®‰å…¨çš„è§£ç 
            missing_padding = len(content) % 4
            if missing_padding:
                content += b'=' * (4 - missing_padding)
            decoded_bytes = base64.urlsafe_b64decode(content)
            return decoded_bytes.decode('utf-8')
        except Exception as e2:
            console.print(f"[bold red]è§£ç å¤±è´¥: {e1} | {e2}[/bold red]")
            return content  # å¦‚æœæ‰€æœ‰è§£ç éƒ½å¤±è´¥ï¼Œè¿”å›åŸå§‹å†…å®¹

def parse_ss_url(ss_url):
    """è§£æ Shadowsocks URL"""
    try:
        if ss_url.startswith("ss://"):
            parsed = urlparse(ss_url)
            
            # è·å– userinfo@server:port éƒ¨åˆ†
            netloc = parsed.netloc
            fragment = unquote(parsed.fragment)  # è§£ç URLç¼–ç çš„ç‰‡æ®µ
            
            # åˆ†ç¦» userinfo@server:port å’Œå¯èƒ½çš„æŸ¥è¯¢å‚æ•°
            if '#' in netloc:
                userinfo_server_port = netloc.split('#')[0]
            else:
                userinfo_server_port = netloc
            
            # åˆ†ç¦» userinfo å’Œ server:port
            if '@' in userinfo_server_port:
                userinfo, server_port = userinfo_server_port.split('@', 1)
            else:
                return None
            
            # è§£ç  userinfo (è¿™éƒ¨åˆ†æ˜¯ base64 ç¼–ç çš„)
            try:
                # ä¿®å¤å¡«å……
                missing_padding = len(userinfo) % 4
                if missing_padding:
                    userinfo += '=' * (4 - missing_padding)
                decoded_userinfo = base64.b64decode(userinfo).decode('utf-8')
            except Exception as e:
                return None
            
            # åˆ†ç¦» method:password
            if ':' in decoded_userinfo:
                method, password = decoded_userinfo.split(':', 1)
            else:
                return None
            
            # åˆ†ç¦» server å’Œ port
            if ':' in server_port:
                server, port_str = server_port.rsplit(':', 1)
                try:
                    port = int(port_str)
                except ValueError:
                    return None
            else:
                return None
            
            # ä½¿ç”¨ç‰‡æ®µä½œä¸ºåç§°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨æœåŠ¡å™¨å’Œç«¯å£
            name = fragment if fragment else f"{server}:{port}"
            # æ¸…ç†èŠ‚ç‚¹åç§°ä¸­çš„ç‰¹æ®Šå­—ç¬¦
            name = re.sub(r'[,;:$]', '-', name)
            
            return {
                "name": name,
                "type": "ss",
                "server": server,
                "port": port,
                "cipher": method,
                "password": password
            }
        return None
    except Exception as e:
        console.print(f"[bold red]è§£æ ss é“¾æ¥æ—¶å‡ºé”™: {e}[/bold red]")
        return None

def fetch_and_parse_subscriptions(urls):
    """è·å–å¹¶è§£ææ‰€æœ‰è®¢é˜…é“¾æ¥"""
    all_nodes = []
    
    # æ·»åŠ è¯·æ±‚å¤´æ¥æ¨¡æ‹ŸçœŸå®æµè§ˆå™¨è¯·æ±‚
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        transient=True,
    ) as progress:
        task = progress.add_task("[cyan]æ­£åœ¨è·å–è®¢é˜…...", total=len(urls))
        
        for url in urls:
            try:
                response = requests.get(url, headers=headers)
                response.raise_for_status()
                
                # è§£ç å†…å®¹
                decoded_content = decode_subscription_content(response.text)
                if not decoded_content:
                    console.print(f"[bold yellow]è­¦å‘Š: æ— æ³•è§£ç è®¢é˜…å†…å®¹ {url}[/bold yellow]")
                    continue
                
                # æŒ‰è¡Œåˆ†å‰²
                lines = decoded_content.splitlines()
                
                # è§£ææ¯ä¸ªèŠ‚ç‚¹
                for line in lines:
                    if line.startswith("ss://"):
                        node = parse_ss_url(line)
                        if node:
                            # è¿‡æ»¤æ‰ä¿¡æ¯æ€§èŠ‚ç‚¹ï¼ˆæ£€æŸ¥èŠ‚ç‚¹åç§°æ˜¯å¦åŒ…å«å…¸å‹çš„æœåŠ¡å™¨ä¿¡æ¯ï¼‰
                            name = node["name"]
                            if not any(keyword in name for keyword in ["å‰©ä½™æµé‡", "è·ç¦»ä¸‹æ¬¡", "å¥—é¤åˆ°æœŸ", "é‡ç½®", "åˆ°æœŸ"]):
                                all_nodes.append(node)
                            
                progress.update(task, advance=1)
            except Exception as e:
                console.print(f"[bold red]è·å–æˆ–è§£æè®¢é˜… {url} æ—¶å‡ºé”™: {e}[/bold red]")
                
    return all_nodes

def extract_region(name):
    """ä»èŠ‚ç‚¹åç§°ä¸­æå–åœ°åŒº"""
    # è½¬æ¢ä¸ºå¤§å†™ä»¥ä¾¿åŒ¹é…
    name_upper = name.upper()
    
    # å¸¸è§åœ°åŒºä»£ç æ˜ å°„
    region_mapping = {
        # äºšæ´²
        "HK": "HK", "HONG KONG": "HK", "é¦™æ¸¯": "HK", "ğŸ‡­ğŸ‡°": "HK",
        "SG": "SG", "SINGAPORE": "SG", "æ–°åŠ å¡": "SG", "ğŸ‡¸ğŸ‡¬": "SG",
        "JP": "JP", "JAPAN": "JP", "æ—¥æœ¬": "JP", "ğŸ‡¯ğŸ‡µ": "JP",
        "KR": "KR", "KOREA": "KR", "éŸ©å›½": "KR", "ğŸ‡°ğŸ‡·": "KR",
        "TW": "TW", "TAIWAN": "TW", "å°æ¹¾": "TW", "ğŸ‡¨ğŸ‡³": "TW",
        "IN": "IN", "INDIA": "IN", "å°åº¦": "IN", "ğŸ‡®ğŸ‡³": "IN",
        
        # æ¬§æ´²
        "UK": "UK", "UNITED KINGDOM": "UK", "è‹±å›½": "UK", "ğŸ‡¬ğŸ‡§": "UK",
        "DE": "DE", "GERMANY": "DE", "å¾·å›½": "DE", "ğŸ‡©ğŸ‡ª": "DE",
        "FR": "FR", "FRANCE": "FR", "æ³•å›½": "FR", "ğŸ‡«ğŸ‡·": "FR",
        "NL": "NL", "NETHERLANDS": "NL", "è·å…°": "NL", "ğŸ‡³ğŸ‡±": "NL",
        "RU": "RU", "RUSSIA": "RU", "ä¿„ç½—æ–¯": "RU", "ğŸ‡·ğŸ‡º": "RU",
        
        # åŒ—ç¾
        "US": "US", "USA": "US", "UNITED STATES": "US", "ç¾å›½": "US", "ğŸ‡ºğŸ‡¸": "US",
        "CA": "CA", "CANADA": "CA", "åŠ æ‹¿å¤§": "CA", "ğŸ‡¨ğŸ‡¦": "CA",
        
        # å¤§æ´‹æ´²
        "AU": "AU", "AUSTRALIA": "AU", "æ¾³å¤§åˆ©äºš": "AU", "ğŸ‡¦ğŸ‡º": "AU",
    }
    
    # å°è¯•åŒ¹é…åœ°åŒºä»£ç 
    for keyword, region in region_mapping.items():
        if keyword in name_upper:
            return region
            
    # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ï¼Œè¿”å›é»˜è®¤å€¼
    return "OTHER"

def group_nodes_by_region(nodes):
    """æŒ‰åœ°åŒºå¯¹èŠ‚ç‚¹è¿›è¡Œåˆ†ç»„"""
    groups = {}
    
    for node in nodes:
        region = extract_region(node["name"])
        if region not in groups:
            groups[region] = []
        groups[region].append(node)
        
    return groups

def generate_config(nodes, output_file):
    """ç”Ÿæˆ Clash é…ç½®æ–‡ä»¶"""
    # æŒ‰åœ°åŒºåˆ†ç»„
    region_groups = group_nodes_by_region(nodes)
    
    # åŸºç¡€é…ç½®
    config = {
        "port": 7890,
        "socks-port": 7891,
        "allow-lan": False,
        "mode": "rule",
        "log-level": "info",
        "external-controller": "127.0.0.1:9090",
        "proxies": nodes,
        "proxy-groups": [],
        "rules": [
            "MATCH,PROXY"
        ]
    }
    
    # åˆ›å»ºä»£ç†ç»„
    proxy_groups = []
    
    # æ‰‹åŠ¨é€‰æ‹©ç»„ï¼ŒåŒ…å«æ‰€æœ‰èŠ‚ç‚¹
    manual_group = {
        "name": "MANUAL-SELECT",
        "type": "select",
        "proxies": [node["name"] for node in nodes]
    }
    proxy_groups.append(manual_group)
    
    # åœ°åŒºåˆ†ç»„
    region_group_names = []
    for region, region_nodes in region_groups.items():
        if region_nodes:  # ç¡®ä¿æœ‰èŠ‚ç‚¹
            group_name = f" {region}"  # å‰é¢åŠ ç©ºæ ¼ä»¥ç¬¦åˆ Clash å‘½åä¹ æƒ¯
            region_group_names.append(group_name)
            
            group = {
                "name": group_name,
                "type": "url-test",
                "url": "http://www.gstatic.com/generate_204",
                "interval": 300,
                "proxies": [node["name"] for node in region_nodes]
            }
            proxy_groups.append(group)
    
    # ä¸»é€‰æ‹©ç»„
    main_group = {
        "name": "PROXY",
        "type": "select",
        "proxies": region_group_names + ["MANUAL-SELECT"]
    }
    proxy_groups.insert(0, main_group)  # å°†ä¸»é€‰æ‹©ç»„æ”¾åœ¨æœ€å‰é¢
    
    config["proxy-groups"] = proxy_groups
    
    # å†™å…¥é…ç½®æ–‡ä»¶
    with open(output_file, 'w', encoding='utf-8') as f:
        yaml.dump(config, f, allow_unicode=True, default_flow_style=False)
    
    console.print(f"[bold green]é…ç½®æ–‡ä»¶å·²ç”Ÿæˆ: {output_file}[/bold green]")
    
    # æ˜¾ç¤ºèŠ‚ç‚¹ç»Ÿè®¡ä¿¡æ¯
    table = Table(title="èŠ‚ç‚¹ç»Ÿè®¡")
    table.add_column("åœ°åŒº", style="cyan")
    table.add_column("èŠ‚ç‚¹æ•°é‡", style="magenta")
    
    for region, region_nodes in region_groups.items():
        table.add_row(region, str(len(region_nodes)))
        
    console.print(table)

def main():
    """ä¸»å‡½æ•°"""
    console.print("[bold blue]æ¬¢è¿ä½¿ç”¨ Clash è®¢é˜…åˆå¹¶å·¥å…·![/bold blue]")
    
    # è·å–è®¢é˜…é“¾æ¥
    urls = get_subscription_urls()
    if not urls:
        console.print("[bold yellow]æ²¡æœ‰è¾“å…¥ä»»ä½•æœ‰æ•ˆçš„è®¢é˜…é“¾æ¥ã€‚[/bold yellow]")
        return
    
    # è·å–è¾“å‡ºæ–‡ä»¶å
    output_file = Prompt.ask("[bold cyan]è¯·è¾“å…¥è¾“å‡ºé…ç½®æ–‡ä»¶å[/bold cyan]", default="config.yaml")
    
    # ç¡®ä¿è¾“å‡ºæ–‡ä»¶åœ¨è„šæœ¬åŒä¸€ç›®å½•ä¸‹
    import os
    script_dir = os.path.dirname(os.path.abspath(__file__))
    output_file = os.path.join(script_dir, output_file)
    
    # è·å–å¹¶è§£æè®¢é˜…
    nodes = fetch_and_parse_subscriptions(urls)
    if not nodes:
        console.print("[bold yellow]æ²¡æœ‰è§£æåˆ°ä»»ä½•æœ‰æ•ˆçš„èŠ‚ç‚¹ã€‚[/bold yellow]")
        return
    
    # ç”Ÿæˆé…ç½®æ–‡ä»¶
    generate_config(nodes, output_file)
    
    console.print("[bold green]æ‰€æœ‰æ“ä½œå·²å®Œæˆï¼[/bold green]")

if __name__ == "__main__":
    main()